{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9988,"databundleVersionId":868324,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dorbezfradj/ship-detection-ps1?scriptVersionId=264047775\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# importation des bibliothéques\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport numpy as np \nfrom skimage.util import montage\nfrom skimage.segmentation import mark_boundaries\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-15T14:26:44.102738Z","iopub.execute_input":"2023-12-15T14:26:44.103347Z","iopub.status.idle":"2023-12-15T14:26:44.107738Z","shell.execute_reply.started":"2023-12-15T14:26:44.103308Z","shell.execute_reply":"2023-12-15T14:26:44.107056Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_image_dir = \"/kaggle/input/airbus-ship-detection/train_v2\"\ntrain_encode_file = \"/kaggle/input/airbus-ship-detection/train_ship_segmentations_v2.csv\"\ntest_image_dir= \"/kaggle/input/airbus-ship-detection/test_v2\"","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:26:44.706053Z","iopub.execute_input":"2023-12-15T14:26:44.70639Z","iopub.status.idle":"2023-12-15T14:26:44.710079Z","shell.execute_reply.started":"2023-12-15T14:26:44.706361Z","shell.execute_reply":"2023-12-15T14:26:44.709446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Le répertoire du train\ntrain_images = os.listdir(train_image_dir)\nprint(f\"Total  {len(train_images)} images dans le répertoire du train . \\nvoici les 5 premières images  : - {train_images[:5]}   \")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:26:44.711343Z","iopub.execute_input":"2023-12-15T14:26:44.711578Z","iopub.status.idle":"2023-12-15T14:26:56.045176Z","shell.execute_reply.started":"2023-12-15T14:26:44.711555Z","shell.execute_reply":"2023-12-15T14:26:56.04439Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Le répertoire du test\ntest_images = os.listdir(test_image_dir)\nprint(f\"Total  {len(test_images)} images dans le répertoire du test . \\nvoici les 5 premières images  : - {test_images[:5]}   \")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:26:56.046061Z","iopub.execute_input":"2023-12-15T14:26:56.046293Z","iopub.status.idle":"2023-12-15T14:27:00.152563Z","shell.execute_reply.started":"2023-12-15T14:26:56.046269Z","shell.execute_reply":"2023-12-15T14:27:00.151886Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# visualiser quelques images de tests\nplt.figure(figsize=(15,15))\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    plt.imshow(cv2.imread(test_image_dir+ '/' +test_images[i]))\n    plt.title(f\"{test_images[i]}\", weight='bold')\n    plt.axis('off')\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:00.153452Z","iopub.execute_input":"2023-12-15T14:27:00.153757Z","iopub.status.idle":"2023-12-15T14:27:04.191158Z","shell.execute_reply.started":"2023-12-15T14:27:00.153728Z","shell.execute_reply":"2023-12-15T14:27:04.190335Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(train_encode_file)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:04.193069Z","iopub.execute_input":"2023-12-15T14:27:04.193336Z","iopub.status.idle":"2023-12-15T14:27:05.288459Z","shell.execute_reply.started":"2023-12-15T14:27:04.19331Z","shell.execute_reply":"2023-12-15T14:27:05.287724Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info() #qlq infomrations sur train_encode_file","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:05.289416Z","iopub.execute_input":"2023-12-15T14:27:05.289664Z","iopub.status.idle":"2023-12-15T14:27:05.31974Z","shell.execute_reply.started":"2023-12-15T14:27:05.28964Z","shell.execute_reply":"2023-12-15T14:27:05.318853Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:05.320897Z","iopub.execute_input":"2023-12-15T14:27:05.321191Z","iopub.status.idle":"2023-12-15T14:27:05.518211Z","shell.execute_reply.started":"2023-12-15T14:27:05.321165Z","shell.execute_reply":"2023-12-15T14:27:05.517513Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:05.519154Z","iopub.execute_input":"2023-12-15T14:27:05.51942Z","iopub.status.idle":"2023-12-15T14:27:05.526716Z","shell.execute_reply.started":"2023-12-15T14:27:05.519393Z","shell.execute_reply":"2023-12-15T14:27:05.526032Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[df[\"ImageId\"]==\"00021ddc3.jpg\"] # dans df, dans la même image nous avons plus d'un navire et chaque navire est rangée dans une ligne de notre table df","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:05.527808Z","iopub.execute_input":"2023-12-15T14:27:05.528085Z","iopub.status.idle":"2023-12-15T14:27:05.557064Z","shell.execute_reply.started":"2023-12-15T14:27:05.528052Z","shell.execute_reply":"2023-12-15T14:27:05.55641Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# construire un dictionnaire dont la clé est l'id de l'image et la valeur est le nombre des navires présents dans l'image\nship_num = {}\n\nfor index, ligne in df.iterrows():\n    id_image = ligne['ImageId']\n    encoding = ligne['EncodedPixels']\n    \n    if pd.isna(encoding) or encoding == \"\":\n        ship_num[id_image] = 0\n    else:\n        if id_image in ship_num:\n            ship_num[id_image] += 1\n        else:\n            ship_num[id_image] = 1\n\nprint(ship_num)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:05.557983Z","iopub.execute_input":"2023-12-15T14:27:05.558249Z","iopub.status.idle":"2023-12-15T14:27:16.46008Z","shell.execute_reply.started":"2023-12-15T14:27:05.558212Z","shell.execute_reply":"2023-12-15T14:27:16.459102Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img=cv2.imread(train_image_dir+\"/30d3f7721.jpg\")\nplt.imshow(img)\nprint(f\"nombres de navires dans cette image est : {ship_num['30d3f7721.jpg'] }\") #on verifie le nombre de navire pour l'image d'id 30d3f7721.jpg","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:16.46116Z","iopub.execute_input":"2023-12-15T14:27:16.461436Z","iopub.status.idle":"2023-12-15T14:27:16.803581Z","shell.execute_reply.started":"2023-12-15T14:27:16.46141Z","shell.execute_reply":"2023-12-15T14:27:16.802773Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(ship_num))\n#coinside avec le nombre unique des element \n# nombre des images","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:16.80469Z","iopub.execute_input":"2023-12-15T14:27:16.805067Z","iopub.status.idle":"2023-12-15T14:27:16.809764Z","shell.execute_reply.started":"2023-12-15T14:27:16.805035Z","shell.execute_reply":"2023-12-15T14:27:16.808979Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transformez le dictionnaire en DataFrame pour faciliter la manipulation des informations\nMonData = pd.DataFrame(list(ship_num.items()), columns=['ImageId', 'ships'])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:16.81066Z","iopub.execute_input":"2023-12-15T14:27:16.810968Z","iopub.status.idle":"2023-12-15T14:27:16.897748Z","shell.execute_reply.started":"2023-12-15T14:27:16.810943Z","shell.execute_reply":"2023-12-15T14:27:16.896775Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MonData.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:16.901918Z","iopub.execute_input":"2023-12-15T14:27:16.902213Z","iopub.status.idle":"2023-12-15T14:27:16.910939Z","shell.execute_reply.started":"2023-12-15T14:27:16.902186Z","shell.execute_reply":"2023-12-15T14:27:16.910116Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#on a verifier que l'image dont l'id est 00003e153.jpg ne presente pas des navires\nimg=cv2.imread(train_image_dir +\"/00003e153.jpg\")\nplt.imshow(img)\nprint(\"cette image d'id \\\"00003e153.jpg\\\" ne represente aucune navire d'aprés le tableau précédent.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:16.912071Z","iopub.execute_input":"2023-12-15T14:27:16.912335Z","iopub.status.idle":"2023-12-15T14:27:17.243098Z","shell.execute_reply.started":"2023-12-15T14:27:16.91231Z","shell.execute_reply":"2023-12-15T14:27:17.242298Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 8)) # Ajuster la taille de la figure\nsns.countplot(data=MonData, x ='ships', palette='Set2')\n# Ajouter des labels et un titre\nplt.title('Distribution du nombre d\\'images', fontsize=16)\nplt.xlabel('Nombre des navires', fontsize=14)\nplt.ylabel('Nombre d\\'occurrences', fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:17.244206Z","iopub.execute_input":"2023-12-15T14:27:17.244476Z","iopub.status.idle":"2023-12-15T14:27:17.866049Z","shell.execute_reply.started":"2023-12-15T14:27:17.244448Z","shell.execute_reply":"2023-12-15T14:27:17.865104Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MonData['ships'].value_counts() # nombre des image qui ont le meme nombre des navires\n#On peut observer un déséquilibre dans la répartition des images en fonction du nombre de navires.","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:17.867348Z","iopub.execute_input":"2023-12-15T14:27:17.867617Z","iopub.status.idle":"2023-12-15T14:27:17.875524Z","shell.execute_reply.started":"2023-12-15T14:27:17.86759Z","shell.execute_reply":"2023-12-15T14:27:17.874644Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# list of image paths\nimage_paths = [\n    os.path.join(train_image_dir, filename) for filename in os.listdir(train_image_dir)\n]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:17.876463Z","iopub.execute_input":"2023-12-15T14:27:17.876754Z","iopub.status.idle":"2023-12-15T14:27:19.724612Z","shell.execute_reply.started":"2023-12-15T14:27:17.876693Z","shell.execute_reply":"2023-12-15T14:27:19.72362Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_paths[10:20]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:19.72581Z","iopub.execute_input":"2023-12-15T14:27:19.726207Z","iopub.status.idle":"2023-12-15T14:27:19.731871Z","shell.execute_reply.started":"2023-12-15T14:27:19.726175Z","shell.execute_reply":"2023-12-15T14:27:19.731159Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.isnull().sum()) # Vérifier s'il y a des valeurs manquantes","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:19.732965Z","iopub.execute_input":"2023-12-15T14:27:19.733212Z","iopub.status.idle":"2023-12-15T14:27:19.775555Z","shell.execute_reply.started":"2023-12-15T14:27:19.733188Z","shell.execute_reply":"2023-12-15T14:27:19.774556Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyse détaillée des images\nfor i in range(5):\n    image = cv2.imread(image_paths[i])\n    hauteur, largeur, canaux = image.shape  # Obtenir les dimensions de l'image\n    taille_image = hauteur * largeur       # Calculer la taille de l'image\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    plt.title(f\"Image {i + 1}\")\n    plt.axis('off')\n    plt.show()\n    print(f\"Dimensions de l'image : {hauteur} x {largeur} pixels\")\n    print(f\"Nombre de canaux : {canaux}\")\n    print(f\"Taille de l'image : {taille_image} pixels\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:19.776633Z","iopub.execute_input":"2023-12-15T14:27:19.776995Z","iopub.status.idle":"2023-12-15T14:27:20.837953Z","shell.execute_reply.started":"2023-12-15T14:27:19.776963Z","shell.execute_reply":"2023-12-15T14:27:20.837165Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('nombre des images dans csv ',len(df))\nprint('nombre des images dans fichier image ',len(image_paths))","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:20.839135Z","iopub.execute_input":"2023-12-15T14:27:20.839414Z","iopub.status.idle":"2023-12-15T14:27:20.843424Z","shell.execute_reply.started":"2023-12-15T14:27:20.839387Z","shell.execute_reply":"2023-12-15T14:27:20.842819Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nombre_images_sans_navire = 0\nnombre_images_avec_navire = 0\n\n# Parcourez le dictionnaire ship_num\nfor nombre_navires in ship_num.values():\n    if nombre_navires == 0:\n        nombre_images_sans_navire += 1\n    else:\n        nombre_images_avec_navire += 1\n\n# Créez deux listes pour les abscisses et les ordonnées du graphique\ncategories = ['Sans Navire', 'Avec Navire']\nnombre_images = [nombre_images_sans_navire, nombre_images_avec_navire]\nprint(\"le nombre des images sans navire\",nombre_images_sans_navire)\nprint(\"le nombre des images avec navire\",nombre_images_avec_navire)\n# Créez un graphique à barres\nplt.bar(categories, nombre_images)\n\n# Étiquetez les axes du graphique\nplt.xlabel('Catégorie')\nplt.ylabel('Nombre d\\'images')\n\n# Affichez le graphique\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:20.844274Z","iopub.execute_input":"2023-12-15T14:27:20.844495Z","iopub.status.idle":"2023-12-15T14:27:20.978432Z","shell.execute_reply.started":"2023-12-15T14:27:20.844472Z","shell.execute_reply":"2023-12-15T14:27:20.977744Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Créer une nouvelle colonne 'Size' qui contient le nombre de pixels par navire\ndf['Size'] = df['EncodedPixels'].apply(lambda x: 0 if pd.isna(x) else sum(map(int, str(x).split()[1::2])))\n\n# Grouper les données par taille et compter le nombre de navires de chaque taille\ntailles_navires = df[df['Size'] > 0]['Size'].value_counts().reset_index()\ntailles_navires.columns = ['Taille du Navire (en pixels)', 'Nombre de Navires']\n\n# Trier les données par taille croissante\ntailles_navires = tailles_navires.sort_values(by='Taille du Navire (en pixels)')\n\n# Tracer le graphique\nplt.figure(figsize=(12, 6))\nplt.hist(tailles_navires['Taille du Navire (en pixels)'], bins=50, color='skyblue', edgecolor='black')\n#plt.bar(tailles_navires['Taille du Navire (en pixels)'], tailles_navires['Nombre de Navires'])\nplt.title('Nombre de Navires en fonction de la Taille')\nplt.xlabel('Taille du Navire (en pixels)')\nplt.ylabel('Nombre de Navires')\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:20.979506Z","iopub.execute_input":"2023-12-15T14:27:20.980027Z","iopub.status.idle":"2023-12-15T14:27:22.510556Z","shell.execute_reply.started":"2023-12-15T14:27:20.979991Z","shell.execute_reply":"2023-12-15T14:27:22.509814Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['file_size_kb']=df['ImageId'].map(lambda c_img_id:os.stat(os.path.join(train_image_dir,c_img_id)).st_size/1024) # calcul de taille des fichiers\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:27:22.511664Z","iopub.execute_input":"2023-12-15T14:27:22.511952Z","iopub.status.idle":"2023-12-15T14:57:50.895991Z","shell.execute_reply.started":"2023-12-15T14:27:22.511924Z","shell.execute_reply":"2023-12-15T14:57:50.894997Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:50.897008Z","iopub.execute_input":"2023-12-15T14:57:50.897262Z","iopub.status.idle":"2023-12-15T14:57:50.906396Z","shell.execute_reply.started":"2023-12-15T14:57:50.897237Z","shell.execute_reply":"2023-12-15T14:57:50.905666Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_color_histogram(image_path):\n    image = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convertir l'image de BGR à RGB (Matplotlib utilise le format RGB)\n    plt.imshow(image_rgb)\n    plt.title('Image originale')\n    plt.axis('off')\n    plt.show()\n    r, g, b = cv2.split(image_rgb)  # Diviser l'image en ses canaux de couleur (Rouge, Vert, Bleu)\n    plt.figure(figsize=(12, 4))\n    # Histogramme pour le canal rouge\n    plt.subplot(131)\n    plt.hist(r.flatten(), bins=256, color='red', alpha=0.7, rwidth=0.8)\n    plt.title('Histogramme Rouge')\n    plt.xlabel('Valeur de pixel')\n    plt.ylabel('Fréquence')\n\n    # Histogramme pour le canal vert\n    plt.subplot(132)\n    plt.hist(g.flatten(), bins=256, color='green', alpha=0.7, rwidth=0.8)\n    plt.title('Histogramme Vert')\n    plt.xlabel('Valeur de pixel')\n    plt.ylabel('Fréquence')\n\n    # Histogramme pour le canal bleu\n    plt.subplot(133)\n    plt.hist(b.flatten(), bins=256, color='blue', alpha=0.7, rwidth=0.8)\n    plt.title('Histogramme Bleu')\n    plt.xlabel('Valeur de pixel')\n    plt.ylabel('Fréquence')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:50.907316Z","iopub.execute_input":"2023-12-15T14:57:50.907549Z","iopub.status.idle":"2023-12-15T14:57:50.918284Z","shell.execute_reply.started":"2023-12-15T14:57:50.907525Z","shell.execute_reply":"2023-12-15T14:57:50.917691Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_color_histogram(image_paths[0])\nplot_color_histogram(image_paths[10])\nplot_color_histogram(image_paths[900])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:50.919127Z","iopub.execute_input":"2023-12-15T14:57:50.919344Z","iopub.status.idle":"2023-12-15T14:57:55.498873Z","shell.execute_reply.started":"2023-12-15T14:57:50.919322Z","shell.execute_reply":"2023-12-15T14:57:55.498151Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def orientation_distribution(image_path):\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Charger l'image en niveaux de gris\n    # Appliquer le filtre de Sobel pour obtenir les gradients\n    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n    \n    gradient_orientation = np.arctan2(sobely, sobelx) # Calculer l'orientation des gradients\n    gradient_orientation_degrees = np.degrees(gradient_orientation) # Convertir l'orientation en degrés\n    flattened_orientation = gradient_orientation_degrees.flatten()  # Aplatir l'array pour l'histogramme\n    # Afficher l'image originale\n    plt.subplot(121)\n    plt.imshow(image, cmap='gray')\n    plt.title('Image originale')\n    plt.axis('off')\n    # Afficher l'histogramme des orientations\n    plt.subplot(122)\n    plt.hist(flattened_orientation, bins=36, range=[-180, 180], color='black', alpha=0.7)\n    plt.title('Histogramme des orientations')\n    plt.xlabel('Orientation en degrés')\n    plt.ylabel('Fréquence')\n    plt.tight_layout()  # Ajuster automatiquement les espaces pour éviter le chevauchement\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:55.500031Z","iopub.execute_input":"2023-12-15T14:57:55.500345Z","iopub.status.idle":"2023-12-15T14:57:55.507365Z","shell.execute_reply.started":"2023-12-15T14:57:55.500314Z","shell.execute_reply":"2023-12-15T14:57:55.506681Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"orientation_distribution(image_paths[10])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:55.508353Z","iopub.execute_input":"2023-12-15T14:57:55.508639Z","iopub.status.idle":"2023-12-15T14:57:55.87241Z","shell.execute_reply.started":"2023-12-15T14:57:55.50861Z","shell.execute_reply":"2023-12-15T14:57:55.871717Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**la fréquence maximale du diagramme est de 17500, ce qui correspond à une orientation de 100 degrés. Cela suggère que l'orientation dominante des objets dans l'image est de 100 degrés, qui correspond a l'orientation du navire**","metadata":{}},{"cell_type":"code","source":"for i in range (1,5):\n    orientation_distribution(image_paths[i])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:55.873396Z","iopub.execute_input":"2023-12-15T14:57:55.873644Z","iopub.status.idle":"2023-12-15T14:57:57.438372Z","shell.execute_reply.started":"2023-12-15T14:57:55.873619Z","shell.execute_reply":"2023-12-15T14:57:57.437661Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def detect_keypoints(image_path):\n    image = cv2.imread(image_path)\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    orb = cv2.ORB_create() # Initialiser l'extracteur ORB\n    keypoints, descriptors = orb.detectAndCompute(gray_image, None)  # Détecter les points d'intérêt et les descripteurs avec ORB\n    image_with_keypoints = cv2.drawKeypoints(image, keypoints, None) # Dessiner les points d'intérêt sur l'image\n    # Afficher l'image avec les points d'intérêt\n    plt.imshow(cv2.cvtColor(image_with_keypoints, cv2.COLOR_BGR2RGB))\n    plt.title('Détection de points d\\'intérêt avec ORB (Oriented FAST and Rotated BRIEF)')\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:57.439408Z","iopub.execute_input":"2023-12-15T14:57:57.43969Z","iopub.status.idle":"2023-12-15T14:57:57.444646Z","shell.execute_reply.started":"2023-12-15T14:57:57.439663Z","shell.execute_reply":"2023-12-15T14:57:57.443939Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"detect_keypoints(image_paths[10])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:57.445632Z","iopub.execute_input":"2023-12-15T14:57:57.445901Z","iopub.status.idle":"2023-12-15T14:57:57.681896Z","shell.execute_reply.started":"2023-12-15T14:57:57.445873Z","shell.execute_reply":"2023-12-15T14:57:57.681186Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**on remarque que la plupart des points d'intérêt obtenus par le filtre ORB est sur le navire**","metadata":{}},{"cell_type":"code","source":"def evaluate_sharpness_contrast(image_path):\n    image = cv2.imread(image_path)\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    laplacian = cv2.Laplacian(gray_image, cv2.CV_64F) # Calculer le filtre Laplacien pour évaluer la netteté\n    sharpness = np.var(laplacian) # Calculer la variance de l'image Laplacienne pour la netteté\n    contrast = np.max(gray_image) - np.min(gray_image) # Calculer le contraste de l'image\n    # Normaliser les valeurs entre 0 et 1\n    sharpness_normalized = sharpness / (sharpness + contrast)\n    contrast_normalized = contrast / (sharpness + contrast)\n    # Produire un score global normalisé\n    score_normalized = (sharpness_normalized + contrast_normalized) / 2\n    return score_normalized","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:57.682897Z","iopub.execute_input":"2023-12-15T14:57:57.683157Z","iopub.status.idle":"2023-12-15T14:57:57.688109Z","shell.execute_reply.started":"2023-12-15T14:57:57.683125Z","shell.execute_reply":"2023-12-15T14:57:57.687494Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**on a 192 225 exemples, analyser toutes les images serait trop coûteux en temps d'exécution. Nous nous concentrons donc sur un échantillon de 4000 images pour maintenir l'efficacité de la fonction evaluate_sharpness_contrast et le bloc de code qui calcule le shape**","metadata":{}},{"cell_type":"code","source":"contrast= set() # initialisation d'un ensemble \nfor i in range(4000):\n    pt = image_paths[i]\n    score = evaluate_sharpness_contrast(pt)\n    contrast.add(score)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:57:57.688946Z","iopub.execute_input":"2023-12-15T14:57:57.689182Z","iopub.status.idle":"2023-12-15T14:59:26.408798Z","shell.execute_reply.started":"2023-12-15T14:57:57.689158Z","shell.execute_reply":"2023-12-15T14:59:26.407574Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"contrast","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:59:26.409983Z","iopub.execute_input":"2023-12-15T14:59:26.410269Z","iopub.status.idle":"2023-12-15T14:59:26.415698Z","shell.execute_reply.started":"2023-12-15T14:59:26.410242Z","shell.execute_reply":"2023-12-15T14:59:26.415021Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**on remarque que toutes les images ont le même score de contraste et de netteté**","metadata":{}},{"cell_type":"code","source":"shape_unique = set() \nfor i in range(4000):\n    pt = image_paths[i]\n    image = cv2.imread(image_paths[i]) \n    shape_unique.add(image.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:59:26.416661Z","iopub.execute_input":"2023-12-15T14:59:26.416922Z","iopub.status.idle":"2023-12-15T14:59:59.210517Z","shell.execute_reply.started":"2023-12-15T14:59:26.416898Z","shell.execute_reply":"2023-12-15T14:59:59.20967Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"shape_unique","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:59:59.211514Z","iopub.execute_input":"2023-12-15T14:59:59.211784Z","iopub.status.idle":"2023-12-15T14:59:59.216643Z","shell.execute_reply.started":"2023-12-15T14:59:59.211757Z","shell.execute_reply":"2023-12-15T14:59:59.215977Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**L'EDA nous a fourni une compréhension initiale des caractéristiques des images.Maintenant, nous concentrerons sur les techniques spécifiques de prétraitement des données, y compris la segmentation par un mask binaire, pour extraire des informations plus fines sur les régions d'intérêt vu que La segmentation permettra une détection plus précise des navires surtout dans une distribution uniforme de l'eau ainsi que les positions des navires sont données dans le fichier Csv. Nous explorerons également la sélection du modèle et l'optimisation des hyperparamètres, qui va être pour le moment un U-Net et n'oublions pas l'augmentation des données**","metadata":{}},{"cell_type":"markdown","source":"# **Prétraitement des données**","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape=(768, 768)):\n\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  \n\ndef masks_image(in_mask_list):\n    # Prendre les masques de navire individuels et créer un tableau de masques unique pour tous les navires\n    all_masks = np.zeros((768, 768), dtype = np.uint8)\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks |= rle_decode(mask)\n    return all_masks","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:59:59.217449Z","iopub.execute_input":"2023-12-15T14:59:59.217672Z","iopub.status.idle":"2023-12-15T14:59:59.229009Z","shell.execute_reply.started":"2023-12-15T14:59:59.217649Z","shell.execute_reply":"2023-12-15T14:59:59.228393Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# afficher une image d'entainement et sa masque\nfrom skimage.io import imread\nfor num in [100, 88, 5]:\n    rle_0 = df.query(f'ImageId==\"{train_images[num-1]}\"')['EncodedPixels']\n    img_0 = masks_image(rle_0)\n    original = imread(train_image_dir+\"/\"+train_images[num-1])\n    plt.figure(figsize=(15, 8))\n    plt.subplot(1, 2, 1)\n    plt.title(f\"Original - Train Image {original.shape}\")\n    plt.imshow(original)\n    plt.subplot(1, 2, 2)\n    plt.title(f\"Mask generated from the RLE data for each ship {img_0.shape}\")\n    plt.imshow(img_0, cmap = \"Blues_r\")\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T14:59:59.22979Z","iopub.execute_input":"2023-12-15T14:59:59.230033Z","iopub.status.idle":"2023-12-15T15:00:01.340102Z","shell.execute_reply.started":"2023-12-15T14:59:59.230009Z","shell.execute_reply":"2023-12-15T15:00:01.33936Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MonData['file_size_kb']=MonData['ImageId'].map(lambda c_img_id:os.stat(os.path.join(train_image_dir,c_img_id)).st_size/1024) # calcul de taille des fichiers\nMonData['file_size_kb'].hist()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:00:01.345592Z","iopub.execute_input":"2023-12-15T15:00:01.345902Z","iopub.status.idle":"2023-12-15T15:03:56.407891Z","shell.execute_reply.started":"2023-12-15T15:00:01.345873Z","shell.execute_reply":"2023-12-15T15:03:56.407198Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filtrer les données pour inclure uniquement les entrées dont la taille de fichier est supérieure à 50 ko\nMonData = MonData[MonData.file_size_kb > 50] # Tracer un histogramme de la colonne 'file_size_kb' pour visualiser la distribution des tailles de fichier\nMonData['file_size_kb'].hist()\nMonData.sample(7) # Sélectionner aléatoirement 7 échantillons de l'ensemble de données\nMonData.shape\ndf.drop(['Size'], axis=1, inplace=True) # Supprimer la colonne 'Size' du DataFrame df \n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:56.408913Z","iopub.execute_input":"2023-12-15T15:03:56.409182Z","iopub.status.idle":"2023-12-15T15:03:56.5551Z","shell.execute_reply.started":"2023-12-15T15:03:56.409154Z","shell.execute_reply":"2023-12-15T15:03:56.554403Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MonData.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:56.556263Z","iopub.execute_input":"2023-12-15T15:03:56.556567Z","iopub.status.idle":"2023-12-15T15:03:56.564386Z","shell.execute_reply.started":"2023-12-15T15:03:56.556536Z","shell.execute_reply":"2023-12-15T15:03:56.563744Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split                   \n# Diviser l'ensemble de données 'MonData' en ensembles d'entraînement (train) et de validation (valid)\ntrain, valid = train_test_split(MonData, test_size=0.2, stratify=MonData['ships'])\nprint(\"le shape du dataframe de train est :\",train.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:56.565293Z","iopub.execute_input":"2023-12-15T15:03:56.56557Z","iopub.status.idle":"2023-12-15T15:03:56.829445Z","shell.execute_reply.started":"2023-12-15T15:03:56.56554Z","shell.execute_reply":"2023-12-15T15:03:56.828744Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.merge(df, train) # Fusionner le DataFrame 'df' avec le DataFrame 'train' \ntrain_df.sort_values(by='ImageId') # Trier le DataFrame résultant 'train_df' par la colonne 'ImageId'\n# Afficher le DataFrame 'train_df'\nprint(train_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:56.830335Z","iopub.execute_input":"2023-12-15T15:03:56.830906Z","iopub.status.idle":"2023-12-15T15:03:57.04581Z","shell.execute_reply.started":"2023-12-15T15:03:56.830876Z","shell.execute_reply":"2023-12-15T15:03:57.04497Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**le nombre des lignes de train était 153031 après la division en train et validation mais après le fusionnage la taille de train df à 184071 lignes qui présentent des lignes de la même image mais de navire différent car les lignes de Df représentent des navires et une image peut continuer plusieurs navires**","metadata":{}},{"cell_type":"code","source":"valid_df = pd.merge(df, valid)\nprint(\"le shape du dataframe de validation est:\",valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.046913Z","iopub.execute_input":"2023-12-15T15:03:57.047219Z","iopub.status.idle":"2023-12-15T15:03:57.135679Z","shell.execute_reply.started":"2023-12-15T15:03:57.047193Z","shell.execute_reply":"2023-12-15T15:03:57.134892Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"on trouve:\")\nprint(train_df.shape[0], 'training masks,')\nprint(valid_df.shape[0], 'validation masks.')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.136803Z","iopub.execute_input":"2023-12-15T15:03:57.137113Z","iopub.status.idle":"2023-12-15T15:03:57.141123Z","shell.execute_reply.started":"2023-12-15T15:03:57.137081Z","shell.execute_reply":"2023-12-15T15:03:57.140413Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(data=train_df, x='ships', palette='Set2')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.142038Z","iopub.execute_input":"2023-12-15T15:03:57.1423Z","iopub.status.idle":"2023-12-15T15:03:57.702517Z","shell.execute_reply.started":"2023-12-15T15:03:57.142274Z","shell.execute_reply":"2023-12-15T15:03:57.701862Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# notre but dans ce code et d'essayer de fusionner le nombre des navires par image en deux classes pour balances les différentes images\ntrain_df['grouped_ship_count'] = train_df.ships.map(lambda x: (x+1)//2).clip(0,7)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.703443Z","iopub.execute_input":"2023-12-15T15:03:57.703683Z","iopub.status.idle":"2023-12-15T15:03:57.778012Z","shell.execute_reply.started":"2023-12-15T15:03:57.703659Z","shell.execute_reply":"2023-12-15T15:03:57.77724Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 0 est l'image ne represente aucun navire\n# 1 les images qui presentent un navire et les images qui presentent 2 navires \ntrain_df.grouped_ship_count.value_counts() # Afficher le décompte des valeurs uniques dans la colonne 'grouped_ship_count' du DataFrame 'train_df'","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.778969Z","iopub.execute_input":"2023-12-15T15:03:57.779227Z","iopub.status.idle":"2023-12-15T15:03:57.786343Z","shell.execute_reply.started":"2023-12-15T15:03:57.7792Z","shell.execute_reply":"2023-12-15T15:03:57.785613Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fonction pour échantillonner des entrées en fonction du nombre de navires \ndef sample_ships(in_df, base_rep_val=2100):\n    if in_df['ships'].values[0] == 0: # Vérifier si le nombre de navires est égal à 0\n        return in_df.sample(base_rep_val // 3)   # échantillonner un tiers de la valeur 2100 \n    else:\n        return in_df.sample(base_rep_val)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.787323Z","iopub.execute_input":"2023-12-15T15:03:57.787571Z","iopub.status.idle":"2023-12-15T15:03:57.796358Z","shell.execute_reply.started":"2023-12-15T15:03:57.787545Z","shell.execute_reply":"2023-12-15T15:03:57.795634Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships) # créer un dataframe plus ou moins balancé\nbalanced_train_df.grouped_ship_count.value_counts()\nprint(\"le shape du dataframe equiblibré est :\",balanced_train_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.797224Z","iopub.execute_input":"2023-12-15T15:03:57.797467Z","iopub.status.idle":"2023-12-15T15:03:57.833694Z","shell.execute_reply.started":"2023-12-15T15:03:57.797443Z","shell.execute_reply":"2023-12-15T15:03:57.833041Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pour chaque sous groupe de 0a 7 on va afficher le nombre des image de train groupeés par le nombre des navires\nfor i in range(8):\n    df_val_counts = balanced_train_df[balanced_train_df.grouped_ship_count==i].ships.value_counts()\n    print(f\"Data frame for grouped ship count = {i}:-\\n{df_val_counts}\\nSum of Values:- {df_val_counts.values.sum()}\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.834606Z","iopub.execute_input":"2023-12-15T15:03:57.835038Z","iopub.status.idle":"2023-12-15T15:03:57.849785Z","shell.execute_reply.started":"2023-12-15T15:03:57.835005Z","shell.execute_reply":"2023-12-15T15:03:57.848996Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Visualiser la distubution des données de training avant et après l'équilibrage\nplt.figure(figsize=(15, 5))\nplt.suptitle(\"Train Data\", fontsize=18, color='r', weight='bold')\n\nplt.subplot(1, 2, 1)\nsns.countplot(data=train_df, x='ships', palette='Set2')\nplt.title(\"Ship Counts - Before Balancing\", fontsize=15)\nplt.ylabel(\"Count\", fontsize=13)\nplt.xlabel(\"# Ships in an image\", fontsize=13)\n\nplt.subplot(1, 2, 2)\nsns.countplot(data=balanced_train_df, x='ships', palette='Set2')\nplt.title(\"Ship Counts - After Balancing\", fontsize=15)\nplt.xlabel(\"# Ships in an image\", fontsize=13)\nplt.ylabel(\"Count\", fontsize=13)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:57.850669Z","iopub.execute_input":"2023-12-15T15:03:57.85093Z","iopub.status.idle":"2023-12-15T15:03:58.798894Z","shell.execute_reply.started":"2023-12-15T15:03:57.850904Z","shell.execute_reply":"2023-12-15T15:03:58.798108Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 48 #taille du chaque batch\nIMG_SCALING = (3, 3) #parametre de rédimensionement de l'image\ndef make_image_gen(in_df, batch_size=BATCH_SIZE):\n    all_batches = list(in_df.groupby('ImageId'))\n    out_rgb = []\n    out_mask = []\n    while True: \n        np.random.shuffle(all_batches) # Mélanger l'ordre des lots(batch)\n        for c_img_id, c_masks in all_batches:\n            # Chemin vers l'image RGB\n            rgb_path = os.path.join(train_image_dir, c_img_id)\n            c_img = imread(rgb_path) # Charger l'image\n            c_mask = np.expand_dims(masks_image(c_masks['EncodedPixels'].values), -1) # Créer le masque à partir des encodages de pixels\n            # Redimensionner l'image et le masque si spécifié\n            if IMG_SCALING is not None:\n                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n            \n            # Ajouter l'image et le masque aux listes\n            out_rgb += [c_img]\n            out_mask += [c_mask]            \n            # Si la taille du lot (batch) est atteinte, renvoyer le lot\n            if len(out_rgb) >= batch_size:\n                yield np.stack(out_rgb, 0) / 255.0, np.stack(out_mask, 0)\n                out_rgb, out_mask = [], []  # Réinitialiser les listes pour le prochain lot","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:58.79991Z","iopub.execute_input":"2023-12-15T15:03:58.800215Z","iopub.status.idle":"2023-12-15T15:03:58.807286Z","shell.execute_reply.started":"2023-12-15T15:03:58.800186Z","shell.execute_reply":"2023-12-15T15:03:58.806588Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_gen = make_image_gen(balanced_train_df) #appel de la fonction \n# Image et Mask\ntrain_x, train_y = next(train_gen)\nprint(f\"train_x ~\\nShape: {train_x.shape}\\nvaleur min: {train_x.min()}\\nvaleur max: {train_x.max()}\")\nprint(f\"\\ntrain_y ~\\nShape: {train_y.shape}\\nvaleur min: {train_y.min()}\\nvaleur max: {train_y.max()}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:03:58.808194Z","iopub.execute_input":"2023-12-15T15:03:58.808566Z","iopub.status.idle":"2023-12-15T15:04:00.494191Z","shell.execute_reply.started":"2023-12-15T15:03:58.80854Z","shell.execute_reply":"2023-12-15T15:04:00.493465Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualisation d'un lot d'entraînement\nfrom skimage.segmentation import mark_boundaries\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nbatch_rgb = montage_rgb(train_x) # Créer un montage d'images a partir de pile\nbatch_seg = montage(train_y[:, :,:,0])  # Créer un montage de masques\nbatch_overlap = mark_boundaries(batch_rgb, batch_seg.astype(int)) # Créer des contours autour des navires dans l'image\ntitles = [\"Images\", \"Segmentations\", \"Contours des navires dans les images\"] \ncolors = ['g', 'm', 'b']  \ndisplay = [batch_rgb, batch_seg, batch_overlap]   \nplt.figure(figsize=(25,10))                                                        \nfor i in range(3):                                                                \n    plt.subplot(1, 3, i+1) # Créer le sous-graphique\n    plt.imshow(display[i])                                                         \n    plt.title(titles[i], fontsize=18, color=colors[i])                            \n    plt.axis('off')                                                                \nplt.suptitle(\"Visualisation du Lot\", fontsize=20, color='r', weight='bold') \nplt.tight_layout()                                                                 \n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:04:00.495197Z","iopub.execute_input":"2023-12-15T15:04:00.495527Z","iopub.status.idle":"2023-12-15T15:04:04.143026Z","shell.execute_reply.started":"2023-12-15T15:04:00.495496Z","shell.execute_reply":"2023-12-15T15:04:04.142272Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"VALID_IMG_COUNT = 400 # Taille de lot validation\nvalid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\nprint(f\"valid_x ~\\nShape: {valid_x.shape}\\nvaleur min: {valid_x.min()}\\nvaleur max: {valid_x.max()}\")\nprint(f\"\\nvalid_y ~\\nShape: {valid_y.shape}\\n valeur min: {valid_y.min()}\\nvaleur max: {valid_y.max()}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:04:04.143999Z","iopub.execute_input":"2023-12-15T15:04:04.144261Z","iopub.status.idle":"2023-12-15T15:04:13.340444Z","shell.execute_reply.started":"2023-12-15T15:04:04.144236Z","shell.execute_reply":"2023-12-15T15:04:13.339584Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# on va utiliser ImageDataGenerator pour l'augmentation du dnnées\nfrom keras.preprocessing.image import ImageDataGenerator\n# Paramètres pour la génération d'images augmentées\ndg_args = dict(rotation_range=15,          # Plage de degrés pour les rotations aléatoires\n               horizontal_flip=True,       # Effectue des retournements horizontaux aléatoires\n               vertical_flip=True,         # Effectue des retournements verticaux aléatoires\n               data_format='channels_last')  # channels_last se réfère à (lot, hauteur, largeur, canaux)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:04:13.341524Z","iopub.execute_input":"2023-12-15T15:04:13.34185Z","iopub.status.idle":"2023-12-15T15:04:13.346562Z","shell.execute_reply.started":"2023-12-15T15:04:13.341819Z","shell.execute_reply":"2023-12-15T15:04:13.345866Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_gen = ImageDataGenerator(**dg_args) # Créer un générateur d'images avec les paramètres spécifiés\nlabel_gen = ImageDataGenerator(**dg_args) # Créer un générateur d'étiquettes avec les paramètres spécifiés\n# Définir une fonction pour créer un générateur augmenté\ndef create_aug_gen(in_gen, seed=None):\n    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n    \n    for in_x, in_y in in_gen:\n        seed = np.random.choice(range(9999))  # definir un seed pour avoir la meme augmentation pour l'image et le mask\n        g_x = image_gen.flow(255 * in_x,\n                             batch_size=in_x.shape[0],\n                             seed=seed,\n                             shuffle=False)\n        \n        g_y = label_gen.flow(in_y,\n                             batch_size=in_x.shape[0],\n                             seed=seed,\n                             shuffle=False)\n\n        yield next(g_x) / 255.0, next(g_y) # Normaliser les valeurs des pixels de l'image et de l'étiquette\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:04:13.34749Z","iopub.execute_input":"2023-12-15T15:04:13.347777Z","iopub.status.idle":"2023-12-15T15:04:13.410571Z","shell.execute_reply.started":"2023-12-15T15:04:13.347744Z","shell.execute_reply":"2023-12-15T15:04:13.409749Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Augmenter les données d'entraînement\ncur_gen = create_aug_gen(train_gen, seed=42)\nt_x, t_y = next(cur_gen)\n\n# Afficher les informations sur les données augmentées\nprint('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\nprint('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:04:13.411417Z","iopub.execute_input":"2023-12-15T15:04:13.411644Z","iopub.status.idle":"2023-12-15T15:04:14.940531Z","shell.execute_reply.started":"2023-12-15T15:04:13.41162Z","shell.execute_reply":"2023-12-15T15:04:14.93984Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n# Nombre total d'exemples\ntotal_examples = t_x.shape[0]\n# Définir un seed pour rendre la sélection aléatoire reproductible\nrandom_seed = 3\nrandom.seed(random_seed)\nrandom_indices = random.sample(range(total_examples), 4) # Sélectionner de manière aléatoire des indices pour les exemples à afficher\nfig, axes = plt.subplots(2, 4, figsize=(10,6)) # Affichage de manière aléatoire des exemples d'images et de leurs masques\nfor i, random_index in enumerate(random_indices):\n    # Afficher l'image\n    axes[0, i].imshow(t_x[random_index])\n    axes[0, i].set_title(f\"Image {random_index + 1}\")\n\n    # Afficher le masque\n    axes[1, i].imshow(t_y[random_index])\n    axes[1, i].set_title(f\"Masque {random_index + 1}\")\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:04:14.941487Z","iopub.execute_input":"2023-12-15T15:04:14.941755Z","iopub.status.idle":"2023-12-15T15:04:15.866085Z","shell.execute_reply.started":"2023-12-15T15:04:14.941729Z","shell.execute_reply":"2023-12-15T15:04:15.865355Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Définir une fonction lambda pour créer un montage RGB à partir d'un tableau d'images\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n# Affichage final avant de passer les données au modèle\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(25, 10))\n\n# Afficher le montage RGB des images d'entraînement\nax1.imshow(montage_rgb(t_x), cmap='gray')\nax1.set_title('Images', fontsize=18, color='g')\nax1.axis('off')\n\n# Afficher le montage des masques\nax2.imshow(montage(t_y[:, :, :, 0]), cmap='Blues_r')\nax2.set_title('Masques', fontsize=18, color='r')\nax2.axis('off')\n\n# Afficher les contours autour des navires dans les images d'entraînement\nax3.imshow(mark_boundaries(montage_rgb(t_x), montage(t_y[:, :, :, 0].astype(int))))\nax3.set_title('Boîte englobante', fontsize=18, color='b')\nax3.axis('off')\nplt.tight_layout()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:04:15.867089Z","iopub.execute_input":"2023-12-15T15:04:15.867377Z","iopub.status.idle":"2023-12-15T15:04:18.981453Z","shell.execute_reply.started":"2023-12-15T15:04:15.867348Z","shell.execute_reply":"2023-12-15T15:04:18.98063Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Construction du model**","metadata":{}},{"cell_type":"code","source":"from keras import models, layers\ndef unet(input_size=(256,256,3)):\n    inputs=layers.Input(input_size)\n    c1= layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(inputs)\n    c1=layers.Dropout(0.1)(c1)\n    c1= layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(inputs)\n    p1=layers.MaxPooling2D((2,2))(c1)\n    \n    c2= layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p1)\n    c2=layers.Dropout(0.1)(c2)\n    c2= layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c2)\n    p2=layers.MaxPooling2D((2,2))(c2)\n    \n    c3= layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p2)\n    c3=layers.Dropout(0.1)(c3)\n    c3= layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c3)\n    p3=layers.MaxPooling2D((2,2))(c3)\n    \n    c4= layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p3)\n    c4=layers.Dropout(0.1)(c4)\n    c4= layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c4)\n    p4=layers.MaxPooling2D((2,2))(c4)\n    \n    c5= layers.Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(p4)\n    c5=layers.Dropout(0.1)(c5)\n    c5= layers.Conv2D(256,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c5)\n    \n    u6=layers.Conv2DTranspose(128,(2,2),strides=(2,2),padding='same')(c5)\n    u6=layers.concatenate([u6,c4])\n    c6= layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u6)\n    c6=layers.Dropout(0.2)(c6)\n    c6= layers.Conv2D(128,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c6)\n    \n    u7=layers.Conv2DTranspose(64,(2,2),strides=(2,2),padding='same')(c6)\n    u7=layers.concatenate([u7,c3])\n    c7= layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u7)\n    c7=layers.Dropout(0.2)(c7)\n    c7= layers.Conv2D(64,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c7)\n    \n    u8=layers.Conv2DTranspose(32,(2,2),strides=(2,2),padding='same')(c7)\n    u8=layers.concatenate([u8,c2])\n    c8= layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u8)\n    c8=layers.Dropout(0.2)(c8)\n    c8= layers.Conv2D(32,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c8)\n    \n    u9=layers.Conv2DTranspose(16,(2,2),strides=(2,2),padding='same')(c8)\n    u9=layers.concatenate([u9,c1])\n    c9= layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(u9)\n    c9=layers.Dropout(0.2)(c9)\n    c9= layers.Conv2D(16,(3,3),activation='relu',kernel_initializer='he_normal',padding='same')(c9)\n    \n    out = layers.Conv2D(1,(1,1),activation='sigmoid')(c9)\n    \n    model = models.Model(inputs=[inputs],outputs=[out])\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:34.643422Z","iopub.execute_input":"2023-12-15T15:07:34.644284Z","iopub.status.idle":"2023-12-15T15:07:34.660008Z","shell.execute_reply.started":"2023-12-15T15:07:34.644235Z","shell.execute_reply":"2023-12-15T15:07:34.659178Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nouveau_model=unet()","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:34.982518Z","iopub.execute_input":"2023-12-15T15:07:34.982899Z","iopub.status.idle":"2023-12-15T15:07:35.33888Z","shell.execute_reply.started":"2023-12-15T15:07:34.982867Z","shell.execute_reply":"2023-12-15T15:07:35.33811Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# les differentes layer du modele\nnouveau_model.layers","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:35.537901Z","iopub.execute_input":"2023-12-15T15:07:35.538187Z","iopub.status.idle":"2023-12-15T15:07:35.544039Z","shell.execute_reply.started":"2023-12-15T15:07:35.538161Z","shell.execute_reply":"2023-12-15T15:07:35.54328Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import keras.backend as k\ndef dice_coeff(y_pred,y_true):\n    y_true = k.cast(y_true, dtype=tf.float32)  \n    y_pred = k.cast(y_pred, dtype=tf.float32)\n    intersection= k.sum(y_pred * y_true,axis=[1,2,3])\n    union= k.sum(y_pred,axis=[1,2,3]) + k.sum(y_true,axis=[1,2,3])\n    dice_coefficient = k.mean((2. * intersection+1) / (union+1))\n    return dice_coefficient ","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:35.931138Z","iopub.execute_input":"2023-12-15T15:07:35.931463Z","iopub.status.idle":"2023-12-15T15:07:35.936648Z","shell.execute_reply.started":"2023-12-15T15:07:35.931435Z","shell.execute_reply":"2023-12-15T15:07:35.935874Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def focal_loss(y_pred,y_true, gamma=2,alpha=0.8):\n    y_true = k.cast(y_true, dtype=tf.float32)  \n    y_pred = k.cast(y_pred, dtype=tf.float32)\n    y_pred=k.flatten(y_pred)\n    y_true=k.flatten(y_true)\n    BCE = k.binary_crossentropy(y_pred,y_true)\n    EXP_BCE= k.exp(-BCE)\n    focal_loss= k.mean(alpha * k.pow((1-EXP_BCE),gamma)* BCE)\n    return focal_loss","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:36.453114Z","iopub.execute_input":"2023-12-15T15:07:36.453425Z","iopub.status.idle":"2023-12-15T15:07:36.458733Z","shell.execute_reply.started":"2023-12-15T15:07:36.453399Z","shell.execute_reply":"2023-12-15T15:07:36.458007Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tester la fonction qui calcule le dice_coeff\nresultat_dice_coeff = dice_coeff(train_x, train_y)\nprint(resultat_dice_coeff.numpy())\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:36.891122Z","iopub.execute_input":"2023-12-15T15:07:36.89147Z","iopub.status.idle":"2023-12-15T15:07:37.031931Z","shell.execute_reply.started":"2023-12-15T15:07:36.891442Z","shell.execute_reply":"2023-12-15T15:07:37.031138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nnouveau_model.compile(optimizer=Adam(1e-3,beta_1=1e-6),loss=focal_loss,metrics=[dice_coeff])","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:37.369185Z","iopub.execute_input":"2023-12-15T15:07:37.369869Z","iopub.status.idle":"2023-12-15T15:07:37.450862Z","shell.execute_reply.started":"2023-12-15T15:07:37.369837Z","shell.execute_reply":"2023-12-15T15:07:37.449958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau\nreduce = ReduceLROnPlateau(monitor='val_dice_coeff', factor=0.23,\n                                   patience=3, verbose=1, mode='max',\n                                   min_delta=0.0001, cooldown=2, min_lr=1e-6)\n\nearly = EarlyStopping(monitor=\"val_dice_coeff\", mode=\"max\",\n                      patience=20)\n\ncallbacks_list = [reduce,early]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:37.825093Z","iopub.execute_input":"2023-12-15T15:07:37.825806Z","iopub.status.idle":"2023-12-15T15:07:37.830046Z","shell.execute_reply.started":"2023-12-15T15:07:37.825771Z","shell.execute_reply":"2023-12-15T15:07:37.829333Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aug_gen = create_aug_gen(train_gen)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:38.278618Z","iopub.execute_input":"2023-12-15T15:07:38.278967Z","iopub.status.idle":"2023-12-15T15:07:38.282755Z","shell.execute_reply.started":"2023-12-15T15:07:38.278939Z","shell.execute_reply":"2023-12-15T15:07:38.28199Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nouveau_model.fit(aug_gen,epochs=200,validation_data=(valid_x, valid_y),steps_per_epoch=30,\n                 callbacks=callbacks_list)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T15:07:38.75229Z","iopub.execute_input":"2023-12-15T15:07:38.752613Z","iopub.status.idle":"2023-12-15T16:09:23.760861Z","shell.execute_reply.started":"2023-12-15T15:07:38.752586Z","shell.execute_reply":"2023-12-15T16:09:23.75986Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nouveau_model.save('nouveau_model.h5')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T16:09:46.544523Z","iopub.execute_input":"2023-12-15T16:09:46.545663Z","iopub.status.idle":"2023-12-15T16:09:46.694857Z","shell.execute_reply.started":"2023-12-15T16:09:46.545618Z","shell.execute_reply":"2023-12-15T16:09:46.693636Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nfinal_model=load_model('nouveau_model.h5',custom_objects={'focal_loss':focal_loss,'dice_coeff':dice_coeff})","metadata":{"execution":{"iopub.status.busy":"2023-12-15T16:09:48.585406Z","iopub.execute_input":"2023-12-15T16:09:48.585806Z","iopub.status.idle":"2023-12-15T16:09:49.033467Z","shell.execute_reply.started":"2023-12-15T16:09:48.585772Z","shell.execute_reply":"2023-12-15T16:09:49.032358Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prediction(path, img_id, model):\n    img = imread(os.path.join(path, img_id))\n    img = img[::3, ::3] \n    img=img/255.0# Redimensionner l'image à la taille attendue par le modèle\n    img = np.expand_dims(img, axis=0)\n\n    # Assurez-vous de fournir les données à la méthode predict\n    pred = model.predict(img)\n\n    img = np.squeeze(img, axis=0)\n    predo = np.squeeze(pred, axis=0)\n    return img, pred","metadata":{"execution":{"iopub.status.busy":"2023-12-15T16:19:21.209173Z","iopub.execute_input":"2023-12-15T16:19:21.209591Z","iopub.status.idle":"2023-12-15T16:19:21.215435Z","shell.execute_reply.started":"2023-12-15T16:19:21.209556Z","shell.execute_reply":"2023-12-15T16:19:21.214574Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaluation du modele\nprint(cv2.imread(\"/kaggle/input/airbus-ship-detection/test_v2/00002bd58.jpg\").shape)\nfor sampl in range(20):\n    img,pred = prediction(\"/kaggle/input/airbus-ship-detection/test_v2\",test_images[sampl],final_model)\n    fig=plt.figure(figsize=(8,8))\n    fig.add_subplot(1,2,1)\n    plt.imshow(img)\n    plt.axis('off')\n    \n    pred_squeezed = np.squeeze(pred, axis=0)\n    fig.add_subplot(1,2,2)\n    plt.imshow(pred_squeezed)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T16:19:21.621549Z","iopub.execute_input":"2023-12-15T16:19:21.62256Z","iopub.status.idle":"2023-12-15T16:19:27.433676Z","shell.execute_reply.started":"2023-12-15T16:19:21.622522Z","shell.execute_reply":"2023-12-15T16:19:27.432455Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}